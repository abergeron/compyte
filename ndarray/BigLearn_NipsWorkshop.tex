\documentclass{article} % For LaTeX2e
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{nips11submit_e,times}
\usepackage{natbib}
\usepackage{amsmath}
%\documentstyle[nips10submit_09,times,art10]{article} % For LaTeX 2.09


\title{A Common GPU N dimensions array}


\author{
Frédéric Bastien\thanks{ Use footnote for providing further information
about author (webpage, alternative address)---\emph{not} for acknowledging
funding agencies.} \\
D\'epartement d'Informatique et de Recherche Op\'erationelle\\
Universit\'e de Montr\'eal\\
Montr\'eal, Canada \\
\texttt{nouiz@nouiz.org} \\
\And
Arnaud Bergeron \\
Lisa Laboratory \\
Université de Montréal \\
\texttt{bergearn@iro.umontreal.ca} \\
\AND
Coauthor \\
Affiliation \\
Address \\
\texttt{email} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
Currently there is multiple array/matrix/n-dimensional array
object that exist on the gpu.  This hinder sharing gpu code and cause
duplicate development work. This paper present a proposition and a
first version~\citep{GpuNdArray} for a common gpu n-dimensional array(tensor) on the GPU. It will
work on CUDA and OpenCL. It will be usable in python and C++.
\end{abstract}

\section{Introduction}
Currently there is at least 4 differents gpu array in python:
CudaNdarray(Theano), GPUArray(pycuda) and CUDAMatrix(cudamat),
GPUArray(pyopencl). There is also other implementation like Trust in
C++.  The problem is that they are not compatible with each
others. All of them have the caracteristic of being a subest of a
tensor(n-dimensional array) that support strides like what Numpy
implement on the CPU.  

Strides are a way to have a view on some memory location that for
example view only odd or even row of a matrix. More generally this
allow to make a view on existing tensor memory space while the view
see only some part of it. It accept as definition of part to take for
each dimensions a range of elements with a step different then 1
between each consecutive elements in the view.

We think that one of the reason why there is so many differents bases
objects is that on the gpu, implementing a general tensor with strides
make coding for GPU even harder. This can be easily bypassed by using
function to check/convert some condition on the memory layout. For
example, if a developer want to only consider inputs in C or Fortran order
for one function, he could just call a function on his inputs to convert the input
into its choosed inputs layout.

The lack of a common GPU tensor create many problems. Here is a few:
\begin{itemize}
  \item Duplicate work
  \item Harder to port/reuse code
  \item Harder to find/distribute code
  \item Divides development work
\end{itemize}

All those problem are agravated by the fact that GPU code is
harder/slower to do correctly and fast than serial CPU code.

\subsection{Pitfall to Avoid}
\begin{itemize}
\item Start alone
  \begin{itemize}
  \item We need different people/groups to ``adopt'' the new GpuNdArray
  \end{itemize}
\item Too simple(ex: just a 1d array) - other projects won't adopt as it won't fit there need.
\item Too general - other projects will implement ``light'' version... and not adopt
  \begin{itemize}
  \item Having an easy way to convert/check conditions could alleviate this.
  \end{itemize}
\end{itemize}

\subsection{Goal/Strategy}
The goal is to have a common GPU object that will be used by every body. We think that the best strategy is:

\begin{itemize}
\item Make a n dimensionals array on the gpu that support strides
\item Make the python interface similar to numpy.ndarray
  \begin{itemize}
  \item Easier to attract other peole from python community
  \end{itemize}
\item Have the base object in C to allow collaboration with more project.
  \begin{itemize}
  \item  want people from C, C++, ruby, R, ... all use the same base Gpu ndarray.
  \end{itemize}
\item Be compatible with CUDA and OpenCL
\end{itemize}


We think that for a common GPU object, we need an n dimensionals
array. This is motivated that forcing user to use an object that
support only 1 or 2 dimensions add complexity to the user when he need
to deal with algorithms that have natively more then 2 dimensions. We
don't think that this complexity should be deal by each users for each
such problems. Having a base object that support n-dimensions, remove
this coding complexity from the user point of view.

From the developer point of view, sometimes it is worth to support
strided tensor as inputs. But this is not the case. We don't think
that asking the developers that choose to don't support n-dimensionals
inputs to call a function to assert/convert the inputs memory layout
is something too complicated or time consuming. Especially when those
functions are provided and compared again reimplementing its own objects.

Many times, the inputs layout choosed by the developer of a function
will lead to better memory access pattern then a random memory
layout. So this is not trivial to say that generalizing the
implementation to support general memory layout will lead to
significant performance gain. If someone else want to use this
implementation without having this memory layout conversion, he could
genearalize it himself. But having a working implementaiton is really
useful to get started and help in the frequent case where this is not a
bottleneck in your code.



\section{Existing Implementation}
\subsection{Theano(CudaNdarray)}
Theano~\citep{bergstra+al:2010-scipy}
tensor with strides, float32 only, cuda only
\subsection{PyCUDA/PyOpenCL(GPUArray)}
PyCUDA~\citep{kloeckner_pycuda_2009} and PyOpenCL~\citep{kloeckner_pycuda_2009}.
contiguous memory only, cuda or opencl only(similar interface)?
can use both in the same programme. all dtype
\subsection{cudamat(CUDAMat)}
CUDAMat~\citep{cudamat-TR2009} cuda only, float32 only I think
\subsection{Gnumpy}
Gnumpy~\citep{gnumpy-TR2010} on top of cudamat.
\subsection{Trust}
Trust~\citep{Thrust} vector only. CUDA only, all dtype

\section{Current implementation}
Multiple backend:
Current behavior not wanted
    * No CPU code generated from the python interface(for PyOpenCL and PyCUDA) Gpu code are ok.


\section{Existing Implementation}

\subsection{Functionality}

The current functionality is divided amongst language dependent parts and language independent parts.  What we call language dependent parts are what is tied to a specific GPU toolkit such as CUDA or OpenCL.  These functions take care of allocating memory on the GPU, making GPU-to-GPU copies and transferring data to and from host memory.  

The language independent parts take care of indexing, making views, and provide an API that is very similar to numpy.  This is the part that supports any combination of dimensions and strides.  We are also working on a language independent way to do elementwise operation on these arrays that respect the shape and strides.

Some parts remain to be done to reach our goal.

fct implemented language dependent
cuda
malloc/free
memcopy
memset
from cpu to gpu
from gpu to cpu

gpu agnos:
sub tensor
deepcopy
view
zeros
empty

probably gpu agnos, not sure:
elemwise
elemwise dimensions collapsing


todo:
assignation
reshape
n dimensional tranpose
dot22,gemm
reduce along all dimensions, along one axis or a list of dimensions
reduce dimensions collapsing

\subsection{Files structure}
File structure that allow using Cuda and PyOpenCL use the same code for some functionality.

\section{Benchmarks}

In order to measure the overhead of multiple dimensions and strides (\emph{TODO: strides}) in comparison to existing implementations, we compared some elementwise kernels generated with PyCUDA to some generated using our algorithm.  The timings shown below do not include any transfer time or allocation of output array.  They were made on a \emph{<insert gpu type>}.

INSERT GRAPHICS!!!

These graphics show that ....

\section{Future Plans}
\section{Conclusion}


\section{Preparing PostScript or PDF files}

%\subsection{Margins in LaTeX}
% 
%Most of the margin problems come from figures positioned by hand using
%\verb+\special+ or other commands. We suggest using the command
%\verb+\includegraphics+
%from the graphicx package. Always specify the figure width as a multiple of
%the line width as in the example below using .eps graphics
%\begin{verbatim}
%   \usepackage[dvips]{graphicx} ... 
%   \includegraphics[width=0.8\linewidth]{myfile.eps} 
%\end{verbatim}
%or % Apr 2009 addition
%\begin{verbatim}
%   \usepackage[pdftex]{graphicx} ... 
%   \includegraphics[width=0.8\linewidth]{myfile.pdf} 
%\end{verbatim}
%for .pdf graphics. 
%See section 4.4 in the graphics bundle documentation (http://www.ctan.org/tex-archive/macros/latex/required/graphics/grfguide.ps) 
% 
%A number of width problems arise when LaTeX cannot properly hyphenate a
%line. Please give LaTeX hyphenation hints using the \verb+\-+ command.


\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All
acknowledgments go at the end of the paper. Do not include 
acknowledgments in the anonymized submission, only in the 
final paper. 

\bibliography{strings,strings-shorter,ml,aigaion-shorter}
\bibliographystyle{plain}

\end{document}
